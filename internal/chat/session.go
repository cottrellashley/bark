package chat

import (
	"encoding/json"
	"fmt"
	"net/http"
	"sync"

	"github.com/go-chi/chi/v5"

	"github.com/cottrellashley/opendoc/internal/core"
)

const systemPrompt = `You are OpenDoc AI — the primary interface for a personal site builder and life wiki.

You help users build, manage, and interact with their website content. Users talk to you first, and you help them do everything from creating pages to querying their own data.

The workspace contains markdown (.md) files for site content, a opendoc.yml config for navigation and site settings, and the output is a static website generated by OpenDoc.

## Your capabilities

- **Read, write, create, and edit** files in the workspace (markdown content, YAML config)
- **Trigger site rebuilds** so changes appear instantly in the preview
- **Update site navigation** in opendoc.yml
- **Create new pages** — blog posts, calendars, planners, notes, anything
- **Query existing content** — read files and answer questions about what's in them

## Response formatting — IMPORTANT

Your responses are rendered as **rich markdown** in the chat interface. Use this to make your answers beautiful and informative:

- Use **headings** (##, ###) to organize longer responses
- Use **tables** when presenting structured data (calendars, schedules, comparisons)
- Use **bullet lists** and **numbered lists** for steps and options
- Use **code blocks** with language tags for any code or file content you show
- Use **bold** and *italic* for emphasis
- Use **blockquotes** for callouts or important notes

### When showing file content or data from the workspace

If the user asks "what's on my calendar" or "what events do I have", read the relevant file and present the information in a nicely formatted way — using tables, lists, or whatever suits the data best. Don't just dump raw file contents; transform them into a pleasant, readable format.

### When creating content

- Use proper YAML frontmatter (title, date, tags, description)
- After making file changes, always trigger a build so the preview updates
- Be proactive — suggest improvements and content ideas
- When creating calendars, planners, or structured pages, use markdown tables and HTML where appropriate for rich layouts

### Tone

Be concise but thorough. You're a capable assistant — answer directly, format beautifully, and act on requests without unnecessary confirmation. If the user asks you to create something, just do it.`

// ChatSession holds the conversation state.
type ChatSession struct {
	Messages  []ChatMessage
	Adapter   LLMAdapter
	Workspace string
	BuildFn   BuildFunc
}

// SessionManager manages chat sessions.
type SessionManager struct {
	mu       sync.Mutex
	sessions map[string]*ChatSession
}

// NewSessionManager creates a new session manager.
func NewSessionManager() *SessionManager {
	return &SessionManager{
		sessions: make(map[string]*ChatSession),
	}
}

func (sm *SessionManager) Get(id string) *ChatSession {
	sm.mu.Lock()
	defer sm.mu.Unlock()
	return sm.sessions[id]
}

func (sm *SessionManager) Set(id string, s *ChatSession) {
	sm.mu.Lock()
	defer sm.mu.Unlock()
	sm.sessions[id] = s
}

func (sm *SessionManager) Delete(id string) {
	sm.mu.Lock()
	defer sm.mu.Unlock()
	delete(sm.sessions, id)
}

// SendMessage sends a user message and streams back the response with tool calling.
func SendMessage(session *ChatSession, userMessage string, onChunk func(StreamChunk)) (string, error) {
	session.Messages = append(session.Messages, ChatMessage{Role: "user", Content: userMessage})

	maxIterations := 10
	for maxIterations > 0 {
		maxIterations--

		response, err := session.Adapter.Chat(session.Messages, ToolDefs, onChunk)
		if err != nil {
			return "", err
		}

		session.Messages = append(session.Messages, response)

		// If no tool calls, we're done
		if len(response.ToolCalls) == 0 {
			return response.Content, nil
		}

		// Execute each tool call
		for _, tc := range response.ToolCalls {
			var args map[string]any
			json.Unmarshal([]byte(tc.Function.Arguments), &args)
			if args == nil {
				args = map[string]any{}
			}

			result := ExecuteTool(tc.Function.Name, args, session.Workspace, session.BuildFn)

			session.Messages = append(session.Messages, ChatMessage{
				Role:       "tool",
				Content:    result,
				ToolCallID: tc.ID,
			})
		}
	}

	return "I've reached the maximum number of tool-calling steps. Please try a simpler request.", nil
}

// ── Chat API routes ─────────────────────────────────────────

// RegisterChatRoutes adds chat API endpoints to the router.
func RegisterChatRoutes(r chi.Router, workspace string, buildFn BuildFunc) {
	sm := NewSessionManager()

	// List available models
	r.Get("/api/chat/models", func(w http.ResponseWriter, r *http.Request) {
		models := []map[string]any{
			{
				"id":        "anthropic",
				"name":      "Claude (Anthropic)",
				"available": core.ResolveAPIKey("anthropic") != "",
			},
			{
				"id":        "openai",
				"name":      "GPT (OpenAI)",
				"available": core.ResolveAPIKey("openai") != "",
			},
		}
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]any{"models": models})
	})

	// Send chat message (SSE streaming)
	r.Post("/api/chat", func(w http.ResponseWriter, r *http.Request) {
		var req struct {
			Message   string `json:"message"`
			SessionID string `json:"sessionId"`
			Provider  string `json:"provider"`
		}
		if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
			http.Error(w, `{"error":"invalid request"}`, http.StatusBadRequest)
			return
		}
		if req.Message == "" {
			http.Error(w, `{"error":"message is required"}`, http.StatusBadRequest)
			return
		}

		// Get or create adapter
		adapter, err := createAdapter(req.Provider)
		if err != nil {
			w.Header().Set("Content-Type", "application/json")
			w.WriteHeader(http.StatusBadRequest)
			json.NewEncoder(w).Encode(map[string]string{"error": err.Error()})
			return
		}

		// Get or create session
		sid := req.SessionID
		if sid == "" {
			sid = fmt.Sprintf("session-%d", r.Context().Value(http.LocalAddrContextKey))
		}
		session := sm.Get(sid)
		if session == nil {
			session = &ChatSession{
				Messages:  []ChatMessage{{Role: "system", Content: systemPrompt}},
				Adapter:   adapter,
				Workspace: workspace,
				BuildFn:   buildFn,
			}
			sm.Set(sid, session)
		}

		// Stream response via SSE
		flusher, ok := w.(http.Flusher)
		if !ok {
			http.Error(w, "Streaming unsupported", http.StatusInternalServerError)
			return
		}

		w.Header().Set("Content-Type", "text/event-stream")
		w.Header().Set("Cache-Control", "no-cache")
		w.Header().Set("Connection", "keep-alive")

		// Send session ID
		sidJSON, _ := json.Marshal(map[string]string{"sessionId": sid})
		fmt.Fprintf(w, "event: session\ndata: %s\n\n", sidJSON)
		flusher.Flush()

		finalText, err := SendMessage(session, req.Message, func(chunk StreamChunk) {
			chunkJSON, _ := json.Marshal(chunk)
			fmt.Fprintf(w, "event: chunk\ndata: %s\n\n", chunkJSON)
			flusher.Flush()
		})

		if err != nil {
			errJSON, _ := json.Marshal(map[string]string{"error": err.Error()})
			fmt.Fprintf(w, "event: error\ndata: %s\n\n", errJSON)
		} else {
			completeJSON, _ := json.Marshal(map[string]string{"content": finalText})
			fmt.Fprintf(w, "event: complete\ndata: %s\n\n", completeJSON)
		}
		flusher.Flush()
	})

	// Clear session
	r.Delete("/api/chat/{sessionId}", func(w http.ResponseWriter, r *http.Request) {
		sid := chi.URLParam(r, "sessionId")
		sm.Delete(sid)
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]bool{"cleared": true})
	})
}

func createAdapter(provider string) (LLMAdapter, error) {
	if provider == "" {
		provider = "anthropic"
	}
	switch provider {
	case "anthropic":
		if core.ResolveAPIKey("anthropic") == "" {
			return nil, fmt.Errorf("Anthropic API key not configured. Add it in Settings or set ANTHROPIC_API_KEY environment variable.")
		}
		return NewAnthropicAdapter(), nil
	case "openai":
		if core.ResolveAPIKey("openai") == "" {
			return nil, fmt.Errorf("OpenAI API key not configured. Add it in Settings or set OPENAI_API_KEY environment variable.")
		}
		return NewOpenAIAdapter(), nil
	default:
		return nil, fmt.Errorf("unknown provider: %s. Use 'anthropic' or 'openai'", provider)
	}
}
